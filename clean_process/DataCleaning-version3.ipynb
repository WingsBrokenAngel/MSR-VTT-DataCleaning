{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCleaning\n",
    "We are going to do data cleaning on the MSR-VTT dataset in three steps: \n",
    "- Remove special characters.\n",
    "- Correct spelling mistakes.\n",
    "- Remove duplicated annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile as zf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human annotations from compressed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zf.ZipFile(\"train_val_annotation.zip\", \"r\") as myzip:\n",
    "    train_val = json.load(myzip.open(\"train_val_videodatainfo.json\"))\n",
    "    \n",
    "with zf.ZipFile(\"test_videodatainfo.json.zip\", \"r\") as myzip:\n",
    "    test = json.load(myzip.open(\"test_videodatainfo.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence number in the training set: 130260\n",
      "Sentence number in the validation set: 9940\n",
      "Sentence in the testing set: 59800\n"
     ]
    }
   ],
   "source": [
    "train_val_sentences = train_val['sentences']\n",
    "test_sentences = test['sentences']\n",
    "\n",
    "train_sents = []\n",
    "for s in train_val_sentences:\n",
    "    if int(s['video_id'][5:]) < 6513:\n",
    "        train_sents.append(s)\n",
    "\n",
    "print('Sentence number in the training set:', len(train_sents))\n",
    "        \n",
    "val_sents = []\n",
    "for s in train_val_sentences:\n",
    "    idx = int(s['video_id'][5:])\n",
    "    if 6513 <= idx < 7010:\n",
    "        val_sents.append(s)\n",
    "        \n",
    "print('Sentence number in the validation set:', len(val_sents))\n",
    "\n",
    "test_sents = test_sentences\n",
    "print('Sentence in the testing set:', len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count in the training set: 1207727\n",
      "Word count in the validation set: 91689\n",
      "Word count in the testing set: 557105\n"
     ]
    }
   ],
   "source": [
    "train_word_cnt = 0\n",
    "\n",
    "for s in train_sents:\n",
    "    s = s['caption']\n",
    "    train_word_cnt += len(s.strip().split())\n",
    "\n",
    "print('Word count in the training set:', train_word_cnt)\n",
    "\n",
    "val_word_cnt = 0\n",
    "for s in val_sents:\n",
    "    s = s['caption']\n",
    "    val_word_cnt += len(s.strip().split())\n",
    "print('Word count in the validation set:', val_word_cnt)\n",
    "\n",
    "test_word_cnt = 0\n",
    "for s in test_sents:\n",
    "    s = s['caption']\n",
    "    test_word_cnt += len(s.strip().split())\n",
    "    \n",
    "print('Word count in the testing set:', test_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size in the training set: 23666\n",
      "Vocabulary size in the validation set: 5993\n",
      "Vocabulary size in the testing set: 16001\n"
     ]
    }
   ],
   "source": [
    "def get_word_set(dataset):\n",
    "    word_set = set()\n",
    "    for s in dataset:\n",
    "        caption = s['caption']\n",
    "        words = caption.strip().split()\n",
    "        word_set |= set(words)\n",
    "    return word_set\n",
    "\n",
    "train_word_set = get_word_set(train_sents)\n",
    "val_word_set = get_word_set(val_sents)\n",
    "test_word_set = get_word_set(test_sents)\n",
    "\n",
    "print('Vocabulary size in the training set: {}'.format(len(train_word_set)))\n",
    "print('Vocabulary size in the validation set: {}'.format(len(val_word_set)))\n",
    "print('Vocabulary size in the testing set: {}'.format(len(test_word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sentence length distribution')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_len_list = []\n",
    "for s in train_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "for s in val_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "for s in test_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sent_len_list, list(range(0, 36, 2)), facecolor='g')\n",
    "plt.xlabel('Sentence length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentence length distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the mapping from video to captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos in total: 10000, videos in the training set: 6513, videos in the validation set: 497, videos in the testing set: 2990.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "video2caption = defaultdict(lambda:[])\n",
    "train_set, val_set, test_set = defaultdict(lambda:[]), defaultdict(lambda:[]), defaultdict(lambda:[])\n",
    "\n",
    "for s in train_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    video2caption[vidx].append(s)\n",
    "    train_set[vidx].append(s)\n",
    "    \n",
    "for s in val_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    video2caption[vidx].append(s)\n",
    "    val_set[vidx].append(s)\n",
    "    \n",
    "for s in test_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    video2caption[vidx].append(s)\n",
    "    test_set[vidx].append(s)\n",
    "\n",
    "print('Videos in total: {}, videos in the training set: {}, videos in the validation set: {}, videos in the testing set: {}.'.\n",
    "      format(len(video2caption), len(train_set), len(val_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove special characters\n",
    "\n",
    "Firstly, we will show all the characters existing in the dataset. And then, we try to remove the peculiar ones in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: ['#', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '=', '>', '@', '[', '\\\\', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'é', 'в', '’']\n",
      "Character count: 60\n"
     ]
    }
   ],
   "source": [
    "def get_charset(video2caption):\n",
    "    charset = set()\n",
    "\n",
    "    for vid in video2caption:\n",
    "        captions = video2caption[vid]\n",
    "        for caption in captions:\n",
    "            words = caption['caption'].strip().split()\n",
    "            for word in words:\n",
    "                charset |= set(list(word))\n",
    "    return charset\n",
    "\n",
    "charset = get_charset(video2caption)\n",
    "print('Characters: {}'.format(sorted(list(charset))))\n",
    "print('Character count: {}'.format(len(charset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 1\n",
    "\"#\", \"*\", \"+\", \".\", \":\", \"=\", \">\", \"\\\\\" are removed from the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set examples.\n",
      "Example for '=': an audience watching a group of performet=rs\n",
      "Example for ':': scenes from the movie avengers: age of ultron\n",
      "Example for '\\': an individual describing\\ what he is seeing on his screen\n",
      "Example for '#': reactions to sports vine #20\n",
      "Example for '+': ted ideas worth spreading one of 1000+ ted talks\n",
      "Example for '*': a vehicle on a city road passes a blue car speeding down the road*\n",
      "\n",
      "\n",
      "Validation set examples.\n",
      "Example for '#': com clip from a list and #8 on that list is nicholas brody from homeland (2011) followed by a spooky scary pirate face\n",
      "Example for ':':  annie leblanc  had a huge victory yesterday in the 1660m race with a final time of 4:16\n",
      "\n",
      "\n",
      "Testing set examples.\n",
      "Example for ':': three children battle on the voice kids: philippines\n",
      "Example for '#': entry #10 from a top list showing a play from an nfl game\n",
      "Example for '>': sports highlights are shown on tv>\n",
      "Example for '.': a woman is dacning in the clip.\n",
      "Example for '=': an animation of a black an =d white dog is given food by his owner and he is excited to eat his food\n",
      "Example for '\\': a big fish catch the man in sea while he swimming\\\n",
      "Example for '+': an advertisement about ted talks a new ideas in every weekday is one of the thousands +\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "origin_chars = [\"#\", \"*\", \".\", \":\", \"+\", \"=\", \">\", \"\\\\\"]\n",
    "\n",
    "def show_examples(data_set, chars):\n",
    "    for vidx, sents in data_set.items():\n",
    "        for sent in sents:\n",
    "            for c in chars:\n",
    "                if c in sent['caption']:\n",
    "                    print(\"Example for '{}': {}\".format(c, sent['caption']))\n",
    "                    chars.remove(c)\n",
    "                    break\n",
    "            \n",
    "            \n",
    "chars = copy.deepcopy(origin_chars)\n",
    "print('Training set examples.')\n",
    "show_examples(train_set, chars)\n",
    "        \n",
    "print('\\n\\nValidation set examples.')\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "show_examples(val_set, chars)\n",
    "        \n",
    "        \n",
    "print('\\n\\nTesting set examples.')\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "show_examples(test_set, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set of sentences/videos that are corrected in this step.\n",
    "sent_set = set()\n",
    "vid_set = set()\n",
    "\n",
    "new_video2caption_step1 = defaultdict(lambda: [])\n",
    "\n",
    "for vidx, sents in video2caption.items():\n",
    "    new_sents = []\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace(\"#\", \"\")\n",
    "        new_sent = new_sent.replace(\"*\", \"\")\n",
    "        new_sent = new_sent.replace(\"+\", \"\")\n",
    "        new_sent = new_sent.replace(\".\", \"\")\n",
    "        new_sent = new_sent.replace(\":\", \"\")\n",
    "        new_sent = new_sent.replace(\"=\", \"\")\n",
    "        new_sent = new_sent.replace(\">\", \"\")\n",
    "        new_sent = new_sent.replace(\"\\\\\", \"\")\n",
    "        sent2 = {'video_id': sent['video_id'], 'sen_id': sent['sen_id'], 'caption': new_sent}\n",
    "        new_sents.append(sent2)\n",
    "        if sent['caption'] != new_sent:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "    new_video2caption_step1[vidx] = new_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_1_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\[\\]\"s and \"()\"s will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = re.sub(r\"\\[[\\w \\d/-]+\\]\", \"\", sent['caption'])\n",
    "        if new_sent != sent['caption']:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            new_sent = \" \".join(new_sent.split())\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            \n",
    "            \n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = re.sub(r\"\\([\\w \\d/-]+\\)\", \"\", sent['caption'])\n",
    "        if new_sent != sent['caption']:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            new_sent = \" \".join(new_sent.split())\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "Here is some examples for '\\[' or '\\]' or '(' that appear in the sentences alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two kids are having fun in water]\n",
      "a video of agriculture production]\n",
      " asc (academy-award winning cinematographer speaking about an film\n",
      "man and women getting physical or intimate cuts to a scene of shampoo or lotion dripping out of the bottle (implying i am guessing climax\n",
      "a scene from the movie girls just wanna have fun featuring a male dancer supporting his female partner in a one-armed lift on a dancing tv show as another couple (including actress\n",
      "a man p[laying golf \n",
      "a man with hair is sitting in a p[lace\n",
      "the crazy train ( reed streets  music  with soft ball players in white bottoms and blue tops \n"
     ]
    }
   ],
   "source": [
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        if '[' in sent['caption'] or ']' in sent['caption'] or '(' in sent['caption'] or ')' in sent['caption']:\n",
    "            print(sent['caption'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\[\"s, \"\\]\"s, \"\\(\"s,  that are single, will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "cnt = 0\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace(\"[\", \"\")\n",
    "        new_sent = new_sent.replace(\"]\", \"\")\n",
    "        new_sent = new_sent.replace(\"(\", \"\")\n",
    "        if new_video2caption_step1[vidx][sidx]['caption'] != new_sent:\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            cnt += 1\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_2_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"-\", \"|\", \"'\", \"\\`\", \"\\@\", \"\\_\", \"\\/\" are replace by a space \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for '-': three contestants and host prepare for a low-budget game show\n",
      "Example for '/': someone working on a drawing in ms paint/\n",
      "Example for '@': an advertisement is displayed for the @mattsteffanina twitter profile featuring ariana grande jason derulo and tyga\n",
      "Example for '_': drums are played in the background music video is shown of a small white car in a rural setting the title is travel vlog_1 wicklow\n",
      "Example for '’': visions of apples are portrayed as a woman’s voice comments on the benefits of apples\n"
     ]
    }
   ],
   "source": [
    "origin_chars = [\"-\", \"|\", \"‘\", \"’\", \"@\", \"_\", \"/\"]\n",
    "\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "\n",
    "show_examples(train_set, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6971"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace(\"-\", \" \")\n",
    "        new_sent = new_sent.replace(\"|\", \" \")\n",
    "        new_sent = new_sent.replace(\"‘\", \" \")\n",
    "        new_sent = new_sent.replace(\"’\", \" \")\n",
    "        new_sent = new_sent.replace(\"@\", \" \")\n",
    "        new_sent = new_sent.replace(\"_\", \" \")\n",
    "        new_sent = new_sent.replace(\"/\", \" \")\n",
    "        new_sent = \" \".join(new_sent.split())\n",
    "        if new_video2caption_step1[vidx][sidx]['caption'] != new_sent:\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_3_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'é', 'в' are replaced by \"e\" and \"b\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6978"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vidx, sents  in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace('é', 'e')\n",
    "        new_sent = new_sent.replace('в', 'b')\n",
    "        if new_sent != new_video2caption_step1[vidx][sidx]['caption'] != new_sent:\n",
    "            cnt += 1\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "' & 's are substituted by 'and'. And '&'s that are part of words, are not replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7050"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        if ' & ' in sent['caption']:\n",
    "            new_sent = sent['caption'].replace(' & ', ' and ')\n",
    "            new_sent = ' '.join(new_sent.split())\n",
    "            new_video2caption_step1[vid][sidx]['caption'] = new_sent\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'\\`s' will be replaced by ' s', otherwise it will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7058"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace('`s', ' s')\n",
    "        new_sent = new_sent.replace('`', '')\n",
    "        new_sent = \" \".join(new_sent.split())\n",
    "        if new_video2caption_step1[vid][sidx]['caption'] != new_sent:\n",
    "            new_video2caption_step1[vid][sidx]['caption'] = new_sent\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7247 sentences have been modified in this section.\n",
      "new character set: {'3', 'v', 'p', '7', 'z', 'f', '0', 'k', 's', '2', 'e', 'j', '1', 'q', 'h', 'w', 'c', 't', '5', '%', 'n', 'd', '&', 'o', '$', 'l', 'y', 'g', 'm', 'i', 'u', 'b', '9', 'a', '4', '8', 'x', 'r', '6'}, cnt: 39\n",
      "The number of sentences changed: 7248, videos changed 4190\n"
     ]
    }
   ],
   "source": [
    "with open(\"step1_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)\n",
    "    \n",
    "cnt = 0\n",
    "for vidx, sents in video2caption.items():\n",
    "    for sidx in range(len(sents)):\n",
    "        if video2caption[vidx][sidx]['caption'] != new_video2caption_step1[vidx][sidx]['caption']:\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "print('{} sentences have been modified in this section.'.format(cnt))\n",
    "\n",
    "new_charset = get_charset(new_video2caption_step1)\n",
    "print('new character set: {}, cnt: {}'.format(new_charset, len(new_charset)))\n",
    "print(f'The number of sentences changed: {len(sent_set)}, videos changed {len(vid_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct spelling mistakes\n",
    "In this section, we are going to correct some spelling mistakes detected by `HunSpell`.\n",
    "\n",
    "Firstly, we substitute British English spellings with American English ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 1: a man gets hit in the face with a chair during a wwf wrestling match -> a man gets hit in the face with a chair during a wwe wrestling match\n",
      "example 2: a man is hitting another man with chair in wwf -> a man is hitting another man with chair in wwe\n",
      "example 3: this is a wwf wrestling match -> this is a wwe wrestling match\n",
      "example 4: a man gets hit in the face with a chair during a wwf wrestling match -> a man gets hit in the face with a chair during a wwe wrestling match\n",
      "example 5: a woman is modelling for a piece of clothing -> a woman is modeling for a piece of clothing\n",
      "example 6: a woman is modelling for a piece of clothing -> a woman is modeling for a piece of clothing\n",
      "example 7: there is a man who met another man in this video and he is also travelling in a car -> there is a man who met another man in this video and he is also traveling in a car\n",
      "example 8: a female character fights freddy kreuger -> a female character fights freddy krueger\n",
      "example 9: mortal kombat fatality with freddy kreuger -> mortal kombat fatality with freddy krueger\n",
      "example 10: skarlet defeats freddy kreuger in a video game fight -> skarlet defeats freddy krueger in a video game fight\n",
      "Replace count: 1626.\n"
     ]
    }
   ],
   "source": [
    "with open('english_america.txt', 'r') as fo:\n",
    "    lines = fo.readlines()\n",
    "english2america = {}\n",
    "for line in lines:\n",
    "    word1, word2 = line.strip().split(' -> ')\n",
    "    english2america[word1] = word2\n",
    "    \n",
    "cnt = 0\n",
    "print_cnt = 0\n",
    "# set of sentences or videos that have been changed.\n",
    "sent_set = set()\n",
    "vid_set = set()\n",
    "\n",
    "new_video2caption_step2 = defaultdict(lambda: [])\n",
    "\n",
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        words = sent['caption'].strip().split()\n",
    "        for widx, word in enumerate(words):\n",
    "            if word in english2america:\n",
    "                words[widx] = english2america[word]\n",
    "                cnt += 1\n",
    "        new_sent = \" \".join(words)\n",
    "        if new_video2caption_step1[vid][sidx]['caption'] != new_sent:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            if print_cnt < 10:\n",
    "                print_cnt += 1\n",
    "                print(\"example {}: {} -> {}\".format(print_cnt, new_video2caption_step1[vid][sidx]['caption'], new_sent))\n",
    "        sent['caption'] = new_sent\n",
    "        new_video2caption_step2[vid].append(sent)\n",
    "        \n",
    "print('Replace count: {}.'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we split words that are composed of two individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1: a clip from dragonball z -> a clip from dragon ball z\n",
      "sample 2: a dragonball z scene where a bold man yells kamehame ya -> a dragon ball z scene where a bold man yells kamehame ya\n",
      "sample 3: video game characters are passing by eachother -> video game characters are passing by each other\n",
      "sample 4: a third person videogame character walking into a poke center in the pokemon game -> a third person video game character walking into a poke center in the pokemon game\n",
      "sample 5: a woman talking on talkshow -> a woman talking on talk show\n",
      "sample 6: gameplay of a videogame is shown -> gameplay of a video game is shown\n",
      "sample 7: pokemon character walking in the pokecenter -> pokemon character walking in the pokemon center\n",
      "sample 8: someone is playing pokemon on a gameboy -> someone is playing pokemon on a game boy\n",
      "sample 9: someone playing pokemon on gameboy -> someone playing pokemon on game boy\n",
      "sample 10: a third person videogame character walking into a poke center in the pokemon game -> a third person video game character walking into a poke center in the pokemon game\n",
      "Replace count: 2560.\n"
     ]
    }
   ],
   "source": [
    "with open('split.txt', 'r') as fo:\n",
    "    lines = fo.readlines()\n",
    "split_dict = {}\n",
    "for line in lines:\n",
    "    word1, word2 = line.strip().split(' -> ')\n",
    "    split_dict[word1] = word2\n",
    "    \n",
    "print_cnt = 0\n",
    "for vidx, sents in new_video2caption_step2.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        words = sent['caption'].strip().split()\n",
    "        for widx, word in enumerate(words):\n",
    "            if word in split_dict:\n",
    "                words[widx] = split_dict[word]\n",
    "                cnt += 1\n",
    "        new_sent = \" \".join(words)\n",
    "        \n",
    "        if new_video2caption_step2[vidx][sidx]['caption'] != new_sent:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            if print_cnt < 10:\n",
    "                print_cnt += 1\n",
    "                print('sample {}: {} -> {}'.format(print_cnt, new_video2caption_step2[vidx][sidx]['caption'], new_sent))\n",
    "        sent['caption'] = new_sent            \n",
    "        new_video2caption_step2[vidx][sidx] = sent\n",
    "        \n",
    "print('Replace count: {}.'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, we correct words using hunspell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34693 words have been corrected.\n",
      "27954 sentences and 7829 videos have been corrected.\n"
     ]
    }
   ],
   "source": [
    "import hunspell\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "ParallelNum = 32\n",
    "\n",
    "spellchecker = hunspell.HunSpell('/usr/share/hunspell/en_US.dic', '/usr/share/hunspell/en_US.aff')\n",
    "\n",
    "with open('dictionary.txt', 'r') as fo:\n",
    "    words = fo.readlines()\n",
    "    words = [w.strip() for w in words]\n",
    "\n",
    "for w in words:\n",
    "    spellchecker.add(w)\n",
    "    \n",
    "def correct_words(words):\n",
    "    ret_words = []\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if spellchecker.spell(word):\n",
    "            ret_words.append(word)\n",
    "        else:\n",
    "            suggestions = spellchecker.suggest(word)\n",
    "            if len(suggestions) > 0:\n",
    "                ret_words.append(suggestions[0])\n",
    "                count += 1\n",
    "            else:\n",
    "                ret_words.append(word)\n",
    "    return ret_words, count\n",
    "\n",
    "def correct_videos(video2caption):\n",
    "    cnt = 0\n",
    "    correct_sent_set = set()\n",
    "    correct_vid_set = set()\n",
    "    for vidx, captions in video2caption.items():\n",
    "        for sidx, caption in enumerate(captions):\n",
    "            words, c = correct_words(caption['caption'].strip().split())\n",
    "            cnt += c\n",
    "            video2caption[vidx][sidx]['caption'] = \" \".join(words).lower()\n",
    "            if c > 0:\n",
    "                correct_sent_set.add(caption['sen_id'])\n",
    "                correct_vid_set.add(caption['video_id'])\n",
    "    return video2caption, cnt, correct_sent_set, correct_vid_set\n",
    "\n",
    "\n",
    "with mp.Pool(ParallelNum) as pool:\n",
    "    video_list = [{} for _ in range(ParallelNum)]\n",
    "    for vidx, captions in new_video2caption_step2.items():\n",
    "        video_list[vidx%ParallelNum][vidx] = captions\n",
    "    \n",
    "    results = []\n",
    "    for idx in range(ParallelNum):\n",
    "        results += [pool.apply_async(correct_videos, [video_list[idx]])]\n",
    "    results = [r.get() for r in results]\n",
    "    \n",
    "for r in results:\n",
    "    videos = r[0]\n",
    "    cnt += r[1]\n",
    "    sent_set |= r[2]\n",
    "    vid_set |= r[3]\n",
    "    for key in videos:\n",
    "        new_video2caption_step2[key] = videos[key]\n",
    "        \n",
    "print('{} words have been corrected.'.format(cnt))\n",
    "print(f'{len(sent_set)} sentences and {len(vid_set)} videos have been corrected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample ten videos randomly and check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a women in black dress is explaining about something\n",
      "there is a woman is talking inside a restaurant\n",
      "a baby muppet cartoon is playing in an animated theater\n",
      "a clip from the show muppet babies\n",
      "7 kids on a back deck at a party singing about something\n",
      "a group of children are gathered around a table on a deck singing and dancing\n",
      "a black man in a trench coat sings a song\n",
      "a lil wayne music video\n",
      "a man in blue shirt is swimming and struggling to save himself while rescuers come in time\n",
      "a beach with someone swimming in the water\n",
      "a baby is laying next to the dad and wakes him up in a funny way\n",
      "here the man is playing a with his kids by looking him suddenly and shouting\n",
      "a woman sits in a room and applies makeup to her eyes with a brush\n",
      "there is a woman applying makeup with a small brush\n",
      "a man is running and a women is complaining about it\n",
      "a person seen here running in parking area\n",
      "ingredients are put in a pan with oil to boil it\n",
      "a person is preparing a onion and garlic fry on a oil bowel\n",
      "a clip from a movie trailer\n",
      "a clip from the hunger games\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(10):\n",
    "    idx = random.randint(0, 10000)\n",
    "    print(new_video2caption_step2[idx][0]['caption'], new_video2caption_step2[idx][1]['caption'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step2_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step2, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicated annotations\n",
    "Now, we are going to remove duplicated annotations.\n",
    "\n",
    "Here is the function used to compute sentence similarity with edit distance as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "import numpy as np\n",
    "\n",
    "ED_THRESHOLD = 0\n",
    "\n",
    "def sentence_similarity(sent1, sent2):\n",
    "    words1 = sent1.strip().split()\n",
    "    words2 = sent2.strip().split()\n",
    "    \n",
    "    dp_mat = np.zeros(shape=(len(words1)+1, len(words2)+1), dtype=int)\n",
    "    for idx1 in range(len(words1)):\n",
    "        for idx2 in range(len(words2)):\n",
    "            w_dist = edit_distance(words1[idx1], words2[idx2])\n",
    "            dist0 = dp_mat[idx1, idx2] + (1 if w_dist<=ED_THRESHOLD else 0)\n",
    "            dp_mat[idx1+1, idx2+1] = max(dist0, dp_mat[idx1, idx2+1], dp_mat[idx1+1, idx2])\n",
    "    lcs = dp_mat[len(words1), len(words2)]\n",
    "    similarity = 0.5 * (lcs / len(words1) + lcs / len(words2))\n",
    "    \n",
    "    return similarity, lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example for sentence similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8263888888888888, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"a woman is singing on a music video\"\n",
    "sent2 = \"a young woman is singing in a music video\"\n",
    "\n",
    "sentence_similarity(sent1, sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182267 captions remain.\n",
      "7129 videos that have been deduplicated.\n"
     ]
    }
   ],
   "source": [
    "Threshold = 0.85\n",
    "cnt = 0\n",
    "# The number of videos that have been deduplicated.\n",
    "vids_cnt = 0\n",
    "\n",
    "def remove_duplicate_captions(video2caption):\n",
    "    cnt = 0\n",
    "    vid_cnt = 0\n",
    "    for vidx, captions in video2caption.items():\n",
    "        similar_captions = defaultdict(list)\n",
    "        inserted = np.zeros(shape=(len(captions),), dtype=int)\n",
    "        for cidx1 in range(len(captions)):\n",
    "            if inserted[cidx1]:\n",
    "                continue\n",
    "            similar_captions[cidx1].append(captions[cidx1])\n",
    "            inserted[cidx1] = 1\n",
    "            for cidx2 in range(cidx1 + 1, len(captions)):\n",
    "                if inserted[cidx2]:\n",
    "                    continue\n",
    "\n",
    "                simil, _ = sentence_similarity(captions[cidx1]['caption'], captions[cidx2]['caption'])\n",
    "                if simil >= Threshold:\n",
    "                    similar_captions[cidx1].append(captions[cidx2])\n",
    "                    inserted[cidx2] = 1\n",
    "        \n",
    "        new_captions = [sorted(cs, key=lambda x: len(x['caption']), reverse=True)[0] for _, cs in similar_captions.items()]\n",
    "        cnt += len(new_captions)\n",
    "        if len(video2caption[vidx]) > len(new_captions):\n",
    "            vid_cnt += 1\n",
    "        video2caption[vidx] = new_captions\n",
    "\n",
    "    return video2caption, cnt, vid_cnt\n",
    "\n",
    "videos_list = [{} for _ in range(ParallelNum)]\n",
    "for vidx, captions in new_video2caption_step2.items():\n",
    "    videos_list[vidx%ParallelNum][vidx] = captions\n",
    "\n",
    "with mp.Pool(ParallelNum) as pool:\n",
    "    rlist = []\n",
    "    for vl in videos_list:\n",
    "        rlist.append(pool.apply_async(remove_duplicate_captions, [vl]))\n",
    "    rlist = [r.get() for r in rlist]\n",
    "\n",
    "new_video2caption_step3 = defaultdict(list)\n",
    "\n",
    "for v, c, vid_cnt in rlist:\n",
    "    cnt += c\n",
    "    vids_cnt += vid_cnt\n",
    "    new_video2caption_step3.update(v)\n",
    "    \n",
    "    \n",
    "print('{} captions remain.'.format(cnt))\n",
    "print(f'{vids_cnt} videos that have been deduplicated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_videodatainfo_prob_85_detail.json', 'w') as fo:\n",
    "    json.dump(new_video2caption_step3, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 118552, validation count: 9062, test count: 54653.\n"
     ]
    }
   ],
   "source": [
    "train_cnt, val_cnt, test_cnt = 0, 0, 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step3.items():\n",
    "    if vidx < 6513:\n",
    "        train_cnt += len(sents)\n",
    "    elif vidx < 7010:\n",
    "        val_cnt += len(sents)\n",
    "    else:\n",
    "        test_cnt += len(sents)\n",
    "        \n",
    "print('Train count: {}, validation count: {}, test count: {}.'.format(train_cnt, val_cnt, test_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum caption count is 8, maximum caption count is 20.\n"
     ]
    }
   ],
   "source": [
    "min_cnt, max_cnt = 1000, 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step3.items():\n",
    "    min_cnt = min(min_cnt, len(sents))\n",
    "    max_cnt = max(max_cnt, len(sents))\n",
    "\n",
    "print('minimum caption count is {}, maximum caption count is {}.'.format(min_cnt, max_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify redundant sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.47731624484959 9.0 4.326602390484384\n",
      "7531 2778 976\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "avg_sen_len_list = []\n",
    "\n",
    "\n",
    "for key, val in new_video2caption_step3.items():\n",
    "    for sen in val:\n",
    "        avg_sen_len_list += [len(sen['caption'].strip().split())]\n",
    "    \n",
    "        \n",
    "print(np.mean(avg_sen_len_list), np.median(avg_sen_len_list), np.std(avg_sen_len_list))\n",
    "avg_len, std_len = np.mean(avg_sen_len_list), np.std(avg_sen_len_list)\n",
    "cnt2, cnt3, cnt4 = 0, 0, 0\n",
    "\n",
    "for length in avg_sen_len_list:\n",
    "    if length > avg_len + 2 * std_len:\n",
    "        cnt2 += 1\n",
    "        \n",
    "    if length > avg_len + 3 * std_len:\n",
    "        cnt3 += 1\n",
    "        \n",
    "    if length > avg_len + 4 * std_len:\n",
    "        cnt4 += 1\n",
    "        \n",
    "print(cnt2, cnt3, cnt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['9216, 2, a clip from the music video for this is how we roll a country song that features dirt bikes miraculously not driving right through the band standing on the top of the ramp',\n",
       " '8512, 4, a man is giving information on how bicycling and swimming burns calories he is stating that they both burn calories but it varies on the difficulty level',\n",
       " '9472, 2, a girl wearing a dress stands to the side of the screen while lyrics to a song playing in the background appear on the other side',\n",
       " '7616, 11, an orange lamborghini revs its engine and is speeding onto a street and then a black lamborghini is shown pulling up to a stop sign',\n",
       " '8128, 0, a cartoon character from the spongebob squarepants speaks to the audience but no sounds is heard and then he gets on a bicycle and dons some sort of a hat that looks like a water glass and rides away all the while a subtitle can be read on the lower left side of the screen saying extremity',\n",
       " '9056, 4, a british man driving a red car parks and upon switching the gear into reverse a rear camera pops out of the back of the car',\n",
       " '9056, 11, a man in a car is giving a review on a volkswagen car the car is red with what seems to be a leather interior',\n",
       " '9056, 18, a man on the wheels talking about the easiness of parking and the camera coming out of the logo when reverse gear is on for volkswagen polo',\n",
       " '9120, 8, in a black helmet and ski outfit is leaning forward and holding onto a white pole that is quickly pulling her over a field of snow',\n",
       " '9088, 9, a man in the blue shirt in the water with a surfboard and a shark fin near him right before he goes under']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_sentences = []\n",
    "\n",
    "for vid, sentences in new_video2caption_step3.items():\n",
    "    if vid < 7010:\n",
    "        continue\n",
    "\n",
    "    for sid, sentence in enumerate(sentences):\n",
    "        words = sentence['caption'].strip().split()\n",
    "        if len(words) > avg_len + 3 * std_len:\n",
    "            multiple_sentences.append(\"{}, {}, {}\".format(vid, sid, sentence['caption']))\n",
    "            \n",
    "print(len(multiple_sentences))\n",
    "multiple_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"multiple_sentences.txt\", \"w\") as fo:\n",
    "    for line in multiple_sentences:\n",
    "        fo.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9216, 2, a clip from the music video for this is how we roll a country song that features dirt bikes miraculously not driving right through the band standing on the top of the ramp',\n",
       " '8512, 4, a man is giving information on how bicycling and swimming burns calories he is stating that they both burn calories but it varies on the difficulty level',\n",
       " '9472, 2, a girl wearing a dress stands to the side of the screen while lyrics to a song playing in the background appear on the other side',\n",
       " '7616, 11, an orange lamborghini revs its engine and is speeding onto a street and then a black lamborghini is shown pulling up to a stop sign',\n",
       " '8128, 0, a cartoon character from the spongebob squarepants speaks to the audience but no sounds is heard and then he gets on a bicycle and dons some sort of a hat that looks like a water glass and rides away all the while a subtitle can be read on the lower left side of the screen saying extremity',\n",
       " '9056, 4, a british man driving a red car parks and upon switching the gear into reverse a rear camera pops out of the back of the car',\n",
       " '9056, 11, a man in a car is giving a review on a volkswagen car the car is red with what seems to be a leather interior',\n",
       " '9056, 18, a man on the wheels talking about the easiness of parking and the camera coming out of the logo when reverse gear is on for volkswagen polo',\n",
       " '9120, 8, in a black helmet and ski outfit is leaning forward and holding onto a white pole that is quickly pulling her over a field of snow',\n",
       " '9088, 9, a man in the blue shirt in the water with a surfboard and a shark fin near him right before he goes under']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"multiple_sentences.txt\", \"r\") as fo:\n",
    "    cleaned_sentences = fo.readlines()\n",
    "    cleaned_sentences = [line.strip().lower() for line in cleaned_sentences]\n",
    "    \n",
    "cleaned_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5344,\n",
       " [{'video_id': 'video5344',\n",
       "   'sen_id': 1160,\n",
       "   'caption': 'a 900 lb man is featured in a documentary'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1161,\n",
       "   'caption': 'a guy is talking with a half naked woman in the background'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1162,\n",
       "   'caption': 'a guy talks about how another man is so fat'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1163,\n",
       "   'caption': 'a host talks about a successful large man'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1164,\n",
       "   'caption': 'a male showing off his food while another male provides commentary'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1165,\n",
       "   'caption': 'a man holds a big plate of food and he weighs 910 pounds'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1166,\n",
       "   'caption': 'a man is holding a sandwich'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1167,\n",
       "   'caption': 'a man is talking about a man s weight'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1168,\n",
       "   'caption': 'a man is talking about how much a man weighs and what he has done'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1169,\n",
       "   'caption': 'a man talking about a fat man'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1170,\n",
       "   'caption': 'a man talking about overweight people'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1171,\n",
       "   'caption': 'a man talks about a man with an eating problem'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1172,\n",
       "   'caption': 'a person is reporting about the weight of another man'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1173,\n",
       "   'caption': 'a video about how a fat man is famous for being fat'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1174,\n",
       "   'caption': 'an obese man becomes famous'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1175,\n",
       "   'caption': 'an obese man is wearing a red sweater'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1176,\n",
       "   'caption': 'guys talking about eating'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1177,\n",
       "   'caption': 'man being interviewed about his lifestyle'},\n",
       "  {'video_id': 'video5344',\n",
       "   'sen_id': 1178,\n",
       "   'caption': 'video of a man talking about an overweight man'}])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_video2caption_step3.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modified sentences: 5266, videos: 2522\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "new_video2caption_step4 = copy.deepcopy(new_video2caption_step3)\n",
    "\n",
    "sent_set = set()\n",
    "vid_set = set()\n",
    "for line in cleaned_sentences:\n",
    "    vid, sid, sent = line.strip().split(\", \")\n",
    "    vid, sid = int(vid), int(sid)\n",
    "    sent = sent.strip()\n",
    "    if new_video2caption_step4[vid][sid]['caption'] != sent:\n",
    "        print('old: {}, new: {}'.format(new_video2caption_step4[vid][sid]['caption'], sent))\n",
    "        new_video2caption_step4[vid][sid]['caption'] = sent\n",
    "        sent_set.add(sid + vid * 100)\n",
    "        vid_set.add(vid)\n",
    "        \n",
    "\n",
    "for vid, sents in new_video2caption_step4.items():\n",
    "    if vid >= 7010:\n",
    "        continue\n",
    "    for sidx, s in enumerate(sents):\n",
    "        caption = \" \".join(s['caption'].strip().split()[:18])\n",
    "        if caption != s['caption']:\n",
    "            sent_set.add(vid * 100 + sidx)\n",
    "            vid_set.add(vid)\n",
    "        s['caption'] = caption\n",
    "    new_video2caption_step4[vid] = sents\n",
    "\n",
    "\n",
    "print(f\"modified sentences: {len(sent_set)}, videos: {len(vid_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step4_videodatainfo_detailed.json', 'w') as fo:\n",
    "    json.dump(new_video2caption_step4, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_id': 'video0', 'sen_id': 77300, 'caption': 'a car is shown'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_video2caption_step4[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
