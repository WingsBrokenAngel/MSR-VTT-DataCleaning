{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCleaning\n",
    "We are going to do data cleaning on the MSR-VTT dataset in three steps: \n",
    "- Remove special characters.\n",
    "- Correct spelling mistakes.\n",
    "- Remove duplicated annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile as zf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human annotations from compressed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zf.ZipFile(\"train_val_annotation.zip\", \"r\") as myzip:\n",
    "    train_val = json.load(myzip.open(\"train_val_videodatainfo.json\"))\n",
    "    \n",
    "with zf.ZipFile(\"test_videodatainfo.json.zip\", \"r\") as myzip:\n",
    "    test = json.load(myzip.open(\"test_videodatainfo.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence number in the training set: 130260\n",
      "Sentence number in the validation set: 9940\n",
      "Sentence in the testing set: 59800\n"
     ]
    }
   ],
   "source": [
    "train_val_sentences = train_val['sentences']\n",
    "test_sentences = test['sentences']\n",
    "\n",
    "train_sents = []\n",
    "for s in train_val_sentences:\n",
    "    if int(s['video_id'][5:]) < 6513:\n",
    "        train_sents.append(s)\n",
    "\n",
    "print('Sentence number in the training set:', len(train_sents))\n",
    "        \n",
    "val_sents = []\n",
    "for s in train_val_sentences:\n",
    "    idx = int(s['video_id'][5:])\n",
    "    if 6513 <= idx < 7010:\n",
    "        val_sents.append(s)\n",
    "        \n",
    "print('Sentence number in the validation set:', len(val_sents))\n",
    "\n",
    "test_sents = test_sentences\n",
    "print('Sentence in the testing set:', len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count in the training set: 1207727\n",
      "Word count in the validation set: 91689\n",
      "Word count in the testing set: 557105\n"
     ]
    }
   ],
   "source": [
    "train_word_cnt = 0\n",
    "\n",
    "for s in train_sents:\n",
    "    s = s['caption']\n",
    "    train_word_cnt += len(s.strip().split())\n",
    "\n",
    "print('Word count in the training set:', train_word_cnt)\n",
    "\n",
    "val_word_cnt = 0\n",
    "for s in val_sents:\n",
    "    s = s['caption']\n",
    "    val_word_cnt += len(s.strip().split())\n",
    "print('Word count in the validation set:', val_word_cnt)\n",
    "\n",
    "test_word_cnt = 0\n",
    "for s in test_sents:\n",
    "    s = s['caption']\n",
    "    test_word_cnt += len(s.strip().split())\n",
    "    \n",
    "print('Word count in the testing set:', test_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size in the training set: 23666\n",
      "Vocabulary size in the validation set: 5993\n",
      "Vocabulary size in the testing set: 16001\n"
     ]
    }
   ],
   "source": [
    "def get_word_set(dataset):\n",
    "    word_set = set()\n",
    "    for s in dataset:\n",
    "        caption = s['caption']\n",
    "        words = caption.strip().split()\n",
    "        word_set |= set(words)\n",
    "    return word_set\n",
    "\n",
    "train_word_set = get_word_set(train_sents)\n",
    "val_word_set = get_word_set(val_sents)\n",
    "test_word_set = get_word_set(test_sents)\n",
    "\n",
    "print('Vocabulary size in the training set: {}'.format(len(train_word_set)))\n",
    "print('Vocabulary size in the validation set: {}'.format(len(val_word_set)))\n",
    "print('Vocabulary size in the testing set: {}'.format(len(test_word_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sentence length distribution')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_len_list = []\n",
    "for s in train_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "for s in val_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "for s in test_sents:\n",
    "    sent = s['caption']\n",
    "    sent_len_list.append(len(sent.strip().split()))\n",
    "    \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sent_len_list, list(range(0, 36, 2)), facecolor='g')\n",
    "plt.xlabel('Sentence length')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentence length distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the mapping from video to captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Videos in total: 10000, videos in the training set: 6513, videos in the validation set: 497, videos in the testing set: 2990.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "video2caption = defaultdict(lambda:[])\n",
    "train_set, val_set, test_set = defaultdict(lambda:[]), defaultdict(lambda:[]), defaultdict(lambda:[])\n",
    "\n",
    "for s in train_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    video2caption[vidx].append(s)\n",
    "    train_set[vidx].append(s)\n",
    "    \n",
    "for s in val_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    video2caption[vidx].append(s)\n",
    "    val_set[vidx].append(s)\n",
    "    \n",
    "for s in test_sents:\n",
    "    vidx = int(s['video_id'][5:])\n",
    "    video2caption[vidx].append(s)\n",
    "    test_set[vidx].append(s)\n",
    "\n",
    "print('Videos in total: {}, videos in the training set: {}, videos in the validation set: {}, videos in the testing set: {}.'.\n",
    "      format(len(video2caption), len(train_set), len(val_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove special characters\n",
    "\n",
    "Firstly, we will show all the characters existing in the dataset. And then, we try to remove the peculiar ones in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: ['#', '$', '%', '&', '(', ')', '*', '+', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '=', '>', '@', '[', '\\\\', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', 'é', 'в', '’']\n",
      "Character count: 60\n"
     ]
    }
   ],
   "source": [
    "def get_charset(video2caption):\n",
    "    charset = set()\n",
    "\n",
    "    for vid in video2caption:\n",
    "        captions = video2caption[vid]\n",
    "        for caption in captions:\n",
    "            words = caption['caption'].strip().split()\n",
    "            for word in words:\n",
    "                charset |= set(list(word))\n",
    "    return charset\n",
    "\n",
    "charset = get_charset(video2caption)\n",
    "print('Characters: {}'.format(sorted(list(charset))))\n",
    "print('Character count: {}'.format(len(charset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove 1\n",
    "\"#\", \"*\", \"+\", \".\", \":\", \"=\", \">\", \"\\\\\" are removed from the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set examples.\n",
      "Example for '=': an audience watching a group of performet=rs\n",
      "Example for ':': scenes from the movie avengers: age of ultron\n",
      "Example for '\\': an individual describing\\ what he is seeing on his screen\n",
      "Example for '#': reactions to sports vine #20\n",
      "Example for '+': ted ideas worth spreading one of 1000+ ted talks\n",
      "Example for '*': a vehicle on a city road passes a blue car speeding down the road*\n",
      "\n",
      "\n",
      "Validation set examples.\n",
      "Example for '#': com clip from a list and #8 on that list is nicholas brody from homeland (2011) followed by a spooky scary pirate face\n",
      "Example for ':':  annie leblanc  had a huge victory yesterday in the 1660m race with a final time of 4:16\n",
      "\n",
      "\n",
      "Testing set examples.\n",
      "Example for ':': three children battle on the voice kids: philippines\n",
      "Example for '#': entry #10 from a top list showing a play from an nfl game\n",
      "Example for '>': sports highlights are shown on tv>\n",
      "Example for '.': a woman is dacning in the clip.\n",
      "Example for '=': an animation of a black an =d white dog is given food by his owner and he is excited to eat his food\n",
      "Example for '\\': a big fish catch the man in sea while he swimming\\\n",
      "Example for '+': an advertisement about ted talks a new ideas in every weekday is one of the thousands +\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "origin_chars = [\"#\", \"*\", \".\", \":\", \"+\", \"=\", \">\", \"\\\\\"]\n",
    "\n",
    "def show_examples(data_set, chars):\n",
    "    for vidx, sents in data_set.items():\n",
    "        for sent in sents:\n",
    "            for c in chars:\n",
    "                if c in sent['caption']:\n",
    "                    print(\"Example for '{}': {}\".format(c, sent['caption']))\n",
    "                    chars.remove(c)\n",
    "                    break\n",
    "            \n",
    "            \n",
    "chars = copy.deepcopy(origin_chars)\n",
    "print('Training set examples.')\n",
    "show_examples(train_set, chars)\n",
    "        \n",
    "print('\\n\\nValidation set examples.')\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "show_examples(val_set, chars)\n",
    "        \n",
    "        \n",
    "print('\\n\\nTesting set examples.')\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "show_examples(test_set, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set of sentences/videos that are corrected in this step.\n",
    "sent_set = set()\n",
    "vid_set = set()\n",
    "\n",
    "new_video2caption_step1 = defaultdict(lambda: [])\n",
    "\n",
    "for vidx, sents in video2caption.items():\n",
    "    new_sents = []\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace(\"#\", \"\")\n",
    "        new_sent = new_sent.replace(\"*\", \"\")\n",
    "        new_sent = new_sent.replace(\"+\", \"\")\n",
    "        new_sent = new_sent.replace(\".\", \"\")\n",
    "        new_sent = new_sent.replace(\":\", \"\")\n",
    "        new_sent = new_sent.replace(\"=\", \"\")\n",
    "        new_sent = new_sent.replace(\">\", \"\")\n",
    "        new_sent = new_sent.replace(\"\\\\\", \"\")\n",
    "        sent2 = {'video_id': sent['video_id'], 'sen_id': sent['sen_id'], 'caption': new_sent}\n",
    "        new_sents.append(sent2)\n",
    "        if sent['caption'] != new_sent:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "    new_video2caption_step1[vidx] = new_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_1_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\[\\]\"s and \"()\"s will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = re.sub(r\"\\[[\\w \\d/-]+\\]\", \"\", sent['caption'])\n",
    "        if new_sent != sent['caption']:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            new_sent = \" \".join(new_sent.split())\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            \n",
    "            \n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = re.sub(r\"\\([\\w \\d/-]+\\)\", \"\", sent['caption'])\n",
    "        if new_sent != sent['caption']:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            new_sent = \" \".join(new_sent.split())\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "Here is some examples for '\\[' or '\\]' or '(' that appear in the sentences alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two kids are having fun in water]\n",
      "a video of agriculture production]\n",
      " asc (academy-award winning cinematographer speaking about an film\n",
      "man and women getting physical or intimate cuts to a scene of shampoo or lotion dripping out of the bottle (implying i am guessing climax\n",
      "a scene from the movie girls just wanna have fun featuring a male dancer supporting his female partner in a one-armed lift on a dancing tv show as another couple (including actress\n",
      "a man p[laying golf \n",
      "a man with hair is sitting in a p[lace\n",
      "the crazy train ( reed streets  music  with soft ball players in white bottoms and blue tops \n"
     ]
    }
   ],
   "source": [
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        if '[' in sent['caption'] or ']' in sent['caption'] or '(' in sent['caption'] or ')' in sent['caption']:\n",
    "            print(sent['caption'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\\[\"s, \"\\]\"s, \"\\(\"s,  that are single, will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "cnt = 0\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace(\"[\", \"\")\n",
    "        new_sent = new_sent.replace(\"]\", \"\")\n",
    "        new_sent = new_sent.replace(\"(\", \"\")\n",
    "        if new_video2caption_step1[vidx][sidx]['caption'] != new_sent:\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            cnt += 1\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_2_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"-\", \"|\", \"'\", \"\\`\", \"\\@\", \"\\_\", \"\\/\" are replace by a space \" \"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for '-': three contestants and host prepare for a low-budget game show\n",
      "Example for '/': someone working on a drawing in ms paint/\n",
      "Example for '@': an advertisement is displayed for the @mattsteffanina twitter profile featuring ariana grande jason derulo and tyga\n",
      "Example for '_': drums are played in the background music video is shown of a small white car in a rural setting the title is travel vlog_1 wicklow\n",
      "Example for '’': visions of apples are portrayed as a woman’s voice comments on the benefits of apples\n"
     ]
    }
   ],
   "source": [
    "origin_chars = [\"-\", \"|\", \"‘\", \"’\", \"@\", \"_\", \"/\"]\n",
    "\n",
    "chars = copy.deepcopy(origin_chars)\n",
    "\n",
    "show_examples(train_set, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6971"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace(\"-\", \" \")\n",
    "        new_sent = new_sent.replace(\"|\", \" \")\n",
    "        new_sent = new_sent.replace(\"‘\", \" \")\n",
    "        new_sent = new_sent.replace(\"’\", \" \")\n",
    "        new_sent = new_sent.replace(\"@\", \" \")\n",
    "        new_sent = new_sent.replace(\"_\", \" \")\n",
    "        new_sent = new_sent.replace(\"/\", \" \")\n",
    "        new_sent = \" \".join(new_sent.split())\n",
    "        if new_video2caption_step1[vidx][sidx]['caption'] != new_sent:\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step1_3_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'é', 'в' are replaced by \"e\" and \"b\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6978"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vidx, sents  in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace('é', 'e')\n",
    "        new_sent = new_sent.replace('в', 'b')\n",
    "        if new_sent != new_video2caption_step1[vidx][sidx]['caption'] != new_sent:\n",
    "            cnt += 1\n",
    "            new_video2caption_step1[vidx][sidx]['caption'] = new_sent\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "' & 's are substituted by 'and'. And '&'s that are part of words, are not replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7050"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        if ' & ' in sent['caption']:\n",
    "            new_sent = sent['caption'].replace(' & ', ' and ')\n",
    "            new_sent = ' '.join(new_sent.split())\n",
    "            new_video2caption_step1[vid][sidx]['caption'] = new_sent\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'\\`s' will be replaced by ' s', otherwise it will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7058"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        new_sent = sent['caption'].replace('`s', ' s')\n",
    "        new_sent = new_sent.replace('`', '')\n",
    "        new_sent = \" \".join(new_sent.split())\n",
    "        if new_video2caption_step1[vid][sidx]['caption'] != new_sent:\n",
    "            new_video2caption_step1[vid][sidx]['caption'] = new_sent\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7247 sentences have been modified in this section.\n",
      "new character set: {'e', 'd', 'v', 'w', 'n', 'l', 'q', 't', '%', '0', '5', 'g', 'a', '3', '6', 'p', '4', 'z', 'x', '$', '9', 's', 'u', '2', 'b', 'm', 'y', 'f', 'c', '7', 'o', 'r', '8', '&', 'k', 'j', 'h', 'i', '1'}, cnt: 39\n",
      "The number of sentences changed: 7248, videos changed 4190\n"
     ]
    }
   ],
   "source": [
    "with open(\"step1_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step1, fo)\n",
    "    \n",
    "cnt = 0\n",
    "for vidx, sents in video2caption.items():\n",
    "    for sidx in range(len(sents)):\n",
    "        if video2caption[vidx][sidx]['caption'] != new_video2caption_step1[vidx][sidx]['caption']:\n",
    "            cnt += 1\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            \n",
    "print('{} sentences have been modified in this section.'.format(cnt))\n",
    "\n",
    "new_charset = get_charset(new_video2caption_step1)\n",
    "print('new character set: {}, cnt: {}'.format(new_charset, len(new_charset)))\n",
    "print(f'The number of sentences changed: {len(sent_set)}, videos changed {len(vid_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct spelling mistakes\n",
    "In this section, we are going to correct some spelling mistakes detected by `HunSpell`.\n",
    "\n",
    "Firstly, we substitute British English spellings with American English ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example 1: a man gets hit in the face with a chair during a wwf wrestling match -> a man gets hit in the face with a chair during a wwe wrestling match\n",
      "example 2: a man is hitting another man with chair in wwf -> a man is hitting another man with chair in wwe\n",
      "example 3: this is a wwf wrestling match -> this is a wwe wrestling match\n",
      "example 4: a man gets hit in the face with a chair during a wwf wrestling match -> a man gets hit in the face with a chair during a wwe wrestling match\n",
      "example 5: a woman is modelling for a piece of clothing -> a woman is modeling for a piece of clothing\n",
      "example 6: a woman is modelling for a piece of clothing -> a woman is modeling for a piece of clothing\n",
      "example 7: there is a man who met another man in this video and he is also travelling in a car -> there is a man who met another man in this video and he is also traveling in a car\n",
      "example 8: a female character fights freddy kreuger -> a female character fights freddy krueger\n",
      "example 9: mortal kombat fatality with freddy kreuger -> mortal kombat fatality with freddy krueger\n",
      "example 10: skarlet defeats freddy kreuger in a video game fight -> skarlet defeats freddy krueger in a video game fight\n",
      "Replace count: 1626.\n"
     ]
    }
   ],
   "source": [
    "with open('english_america.txt', 'r') as fo:\n",
    "    lines = fo.readlines()\n",
    "english2america = {}\n",
    "for line in lines:\n",
    "    word1, word2 = line.strip().split(' -> ')\n",
    "    english2america[word1] = word2\n",
    "    \n",
    "cnt = 0\n",
    "print_cnt = 0\n",
    "# set of sentences or videos that have been changed.\n",
    "sent_set = set()\n",
    "vid_set = set()\n",
    "\n",
    "new_video2caption_step2 = defaultdict(lambda: [])\n",
    "\n",
    "for vid, sents in new_video2caption_step1.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        words = sent['caption'].strip().split()\n",
    "        for widx, word in enumerate(words):\n",
    "            if word in english2america:\n",
    "                words[widx] = english2america[word]\n",
    "                cnt += 1\n",
    "        new_sent = \" \".join(words)\n",
    "        if new_video2caption_step1[vid][sidx]['caption'] != new_sent:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            if print_cnt < 10:\n",
    "                print_cnt += 1\n",
    "                print(\"example {}: {} -> {}\".format(print_cnt, new_video2caption_step1[vid][sidx]['caption'], new_sent))\n",
    "        sent['caption'] = new_sent\n",
    "        new_video2caption_step2[vid].append(sent)\n",
    "        \n",
    "print('Replace count: {}.'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we split words that are composed of two individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1: a clip from dragonball z -> a clip from dragon ball z\n",
      "sample 2: a dragonball z scene where a bold man yells kamehame ya -> a dragon ball z scene where a bold man yells kamehame ya\n",
      "sample 3: video game characters are passing by eachother -> video game characters are passing by each other\n",
      "sample 4: a third person videogame character walking into a poke center in the pokemon game -> a third person video game character walking into a poke center in the pokemon game\n",
      "sample 5: a woman talking on talkshow -> a woman talking on talk show\n",
      "sample 6: gameplay of a videogame is shown -> gameplay of a video game is shown\n",
      "sample 7: pokemon character walking in the pokecenter -> pokemon character walking in the pokemon center\n",
      "sample 8: someone is playing pokemon on a gameboy -> someone is playing pokemon on a game boy\n",
      "sample 9: someone playing pokemon on gameboy -> someone playing pokemon on game boy\n",
      "sample 10: a third person videogame character walking into a poke center in the pokemon game -> a third person video game character walking into a poke center in the pokemon game\n",
      "Replace count: 2560.\n"
     ]
    }
   ],
   "source": [
    "with open('split.txt', 'r') as fo:\n",
    "    lines = fo.readlines()\n",
    "split_dict = {}\n",
    "for line in lines:\n",
    "    word1, word2 = line.strip().split(' -> ')\n",
    "    split_dict[word1] = word2\n",
    "    \n",
    "print_cnt = 0\n",
    "for vidx, sents in new_video2caption_step2.items():\n",
    "    for sidx, sent in enumerate(sents):\n",
    "        words = sent['caption'].strip().split()\n",
    "        for widx, word in enumerate(words):\n",
    "            if word in split_dict:\n",
    "                words[widx] = split_dict[word]\n",
    "                cnt += 1\n",
    "        new_sent = \" \".join(words)\n",
    "        \n",
    "        if new_video2caption_step2[vidx][sidx]['caption'] != new_sent:\n",
    "            sent_set.add(sent['sen_id'])\n",
    "            vid_set.add(sent['video_id'])\n",
    "            if print_cnt < 10:\n",
    "                print_cnt += 1\n",
    "                print('sample {}: {} -> {}'.format(print_cnt, new_video2caption_step2[vidx][sidx]['caption'], new_sent))\n",
    "        sent['caption'] = new_sent            \n",
    "        new_video2caption_step2[vidx][sidx] = sent\n",
    "        \n",
    "print('Replace count: {}.'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thirdly, we correct words using hunspell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hunspell'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhunspell\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m ParallelNum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hunspell'"
     ]
    }
   ],
   "source": [
    "import hunspell\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "ParallelNum = 32\n",
    "\n",
    "spellchecker = hunspell.HunSpell('/usr/share/hunspell/en_US.dic', '/usr/share/hunspell/en_US.aff')\n",
    "\n",
    "with open('dictionary.txt', 'r') as fo:\n",
    "    words = fo.readlines()\n",
    "    words = [w.strip() for w in words]\n",
    "\n",
    "for w in words:\n",
    "    spellchecker.add(w)\n",
    "    \n",
    "def correct_words(words):\n",
    "    ret_words = []\n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if spellchecker.spell(word):\n",
    "            ret_words.append(word)\n",
    "        else:\n",
    "            suggestions = spellchecker.suggest(word)\n",
    "            if len(suggestions) > 0:\n",
    "                ret_words.append(suggestions[0])\n",
    "                count += 1\n",
    "            else:\n",
    "                ret_words.append(word)\n",
    "    return ret_words, count\n",
    "\n",
    "def correct_videos(video2caption):\n",
    "    cnt = 0\n",
    "    correct_sent_set = set()\n",
    "    correct_vid_set = set()\n",
    "    for vidx, captions in video2caption.items():\n",
    "        for sidx, caption in enumerate(captions):\n",
    "            words, c = correct_words(caption['caption'].strip().split())\n",
    "            cnt += c\n",
    "            video2caption[vidx][sidx]['caption'] = \" \".join(words).lower()\n",
    "            if c > 0:\n",
    "                correct_sent_set.add(caption['sen_id'])\n",
    "                correct_vid_set.add(caption['video_id'])\n",
    "    return video2caption, cnt, correct_sent_set, correct_vid_set\n",
    "\n",
    "\n",
    "with mp.Pool(ParallelNum) as pool:\n",
    "    video_list = [{} for _ in range(ParallelNum)]\n",
    "    for vidx, captions in new_video2caption_step2.items():\n",
    "        video_list[vidx%ParallelNum][vidx] = captions\n",
    "    \n",
    "    results = []\n",
    "    for idx in range(ParallelNum):\n",
    "        results += [pool.apply_async(correct_videos, [video_list[idx]])]\n",
    "    results = [r.get() for r in results]\n",
    "    \n",
    "for r in results:\n",
    "    videos = r[0]\n",
    "    cnt += r[1]\n",
    "    sent_set |= r[2]\n",
    "    vid_set |= r[3]\n",
    "    for key in videos:\n",
    "        new_video2caption_step2[key] = videos[key]\n",
    "        \n",
    "print('{} words have been corrected.'.format(cnt))\n",
    "print(f'{len(sent_set)} sentences and {len(vid_set)} videos have been corrected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample ten videos randomly and check them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(10):\n",
    "    idx = random.randint(0, 10000)\n",
    "    print(new_video2caption_step2[idx][0]['caption'], new_video2caption_step2[idx][1]['caption'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"step2_videodatainfo_detail.json\", \"w\") as fo:\n",
    "    json.dump(new_video2caption_step2, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicated annotations\n",
    "Now, we are going to remove duplicated annotations.\n",
    "\n",
    "Here is the function used to compute sentence similarity with edit distance as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n",
    "import numpy as np\n",
    "\n",
    "ED_THRESHOLD = 0\n",
    "\n",
    "def sentence_similarity(sent1, sent2):\n",
    "    words1 = sent1.strip().split()\n",
    "    words2 = sent2.strip().split()\n",
    "    \n",
    "    dp_mat = np.zeros(shape=(len(words1)+1, len(words2)+1), dtype=int)\n",
    "    for idx1 in range(len(words1)):\n",
    "        for idx2 in range(len(words2)):\n",
    "            w_dist = edit_distance(words1[idx1], words2[idx2])\n",
    "            dist0 = dp_mat[idx1, idx2] + (1 if w_dist<=ED_THRESHOLD else 0)\n",
    "            dp_mat[idx1+1, idx2+1] = max(dist0, dp_mat[idx1, idx2+1], dp_mat[idx1+1, idx2])\n",
    "    lcs = dp_mat[len(words1), len(words2)]\n",
    "    similarity = 0.5 * (lcs / len(words1) + lcs / len(words2))\n",
    "    \n",
    "    return similarity, lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example for sentence similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"a woman is singing on a music video\"\n",
    "sent2 = \"a young woman is singing in a music video\"\n",
    "\n",
    "sentence_similarity(sent1, sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold = 0.85\n",
    "cnt = 0\n",
    "# The number of videos that have been deduplicated.\n",
    "vids_cnt = 0\n",
    "\n",
    "def remove_duplicate_captions(video2caption):\n",
    "    cnt = 0\n",
    "    vid_cnt = 0\n",
    "    for vidx, captions in video2caption.items():\n",
    "        similar_captions = defaultdict(list)\n",
    "        inserted = np.zeros(shape=(len(captions),), dtype=int)\n",
    "        for cidx1 in range(len(captions)):\n",
    "            if inserted[cidx1]:\n",
    "                continue\n",
    "            similar_captions[cidx1].append(captions[cidx1])\n",
    "            inserted[cidx1] = 1\n",
    "            for cidx2 in range(cidx1 + 1, len(captions)):\n",
    "                if inserted[cidx2]:\n",
    "                    continue\n",
    "\n",
    "                simil, _ = sentence_similarity(captions[cidx1]['caption'], captions[cidx2]['caption'])\n",
    "                if simil >= Threshold:\n",
    "                    similar_captions[cidx1].append(captions[cidx2])\n",
    "                    inserted[cidx2] = 1\n",
    "        \n",
    "        new_captions = [sorted(cs, key=lambda x: len(x['caption']), reverse=True)[0] for _, cs in similar_captions.items()]\n",
    "        cnt += len(new_captions)\n",
    "        if len(video2caption[vidx]) > len(new_captions):\n",
    "            vid_cnt += 1\n",
    "        video2caption[vidx] = new_captions\n",
    "\n",
    "    return video2caption, cnt, vid_cnt\n",
    "\n",
    "videos_list = [{} for _ in range(ParallelNum)]\n",
    "for vidx, captions in new_video2caption_step2.items():\n",
    "    videos_list[vidx%ParallelNum][vidx] = captions\n",
    "\n",
    "with mp.Pool(ParallelNum) as pool:\n",
    "    rlist = []\n",
    "    for vl in videos_list:\n",
    "        rlist.append(pool.apply_async(remove_duplicate_captions, [vl]))\n",
    "    rlist = [r.get() for r in rlist]\n",
    "\n",
    "new_video2caption_step3 = defaultdict(list)\n",
    "\n",
    "for v, c, vid_cnt in rlist:\n",
    "    cnt += c\n",
    "    vids_cnt += vid_cnt\n",
    "    new_video2caption_step3.update(v)\n",
    "    \n",
    "    \n",
    "print('{} captions remain.'.format(cnt))\n",
    "print(f'{vids_cnt} videos that have been deduplicated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step3_videodatainfo_prob_85_detail.json', 'w') as fo:\n",
    "    json.dump(new_video2caption_step3, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cnt, val_cnt, test_cnt = 0, 0, 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step3.items():\n",
    "    if vidx < 6513:\n",
    "        train_cnt += len(sents)\n",
    "    elif vidx < 7010:\n",
    "        val_cnt += len(sents)\n",
    "    else:\n",
    "        test_cnt += len(sents)\n",
    "        \n",
    "print('Train count: {}, validation count: {}, test count: {}.'.format(train_cnt, val_cnt, test_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cnt, max_cnt = 1000, 0\n",
    "\n",
    "for vidx, sents in new_video2caption_step3.items():\n",
    "    min_cnt = min(min_cnt, len(sents))\n",
    "    max_cnt = max(max_cnt, len(sents))\n",
    "\n",
    "print('minimum caption count is {}, maximum caption count is {}.'.format(min_cnt, max_cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify redundant sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "avg_sen_len_list = []\n",
    "\n",
    "\n",
    "for key, val in new_video2caption_step3.items():\n",
    "    for sen in val:\n",
    "        avg_sen_len_list += [len(sen['caption'].strip().split())]\n",
    "    \n",
    "        \n",
    "print(np.mean(avg_sen_len_list), np.median(avg_sen_len_list), np.std(avg_sen_len_list))\n",
    "avg_len, std_len = np.mean(avg_sen_len_list), np.std(avg_sen_len_list)\n",
    "cnt2, cnt3, cnt4 = 0, 0, 0\n",
    "\n",
    "for length in avg_sen_len_list:\n",
    "    if length > avg_len + 2 * std_len:\n",
    "        cnt2 += 1\n",
    "        \n",
    "    if length > avg_len + 3 * std_len:\n",
    "        cnt3 += 1\n",
    "        \n",
    "    if length > avg_len + 4 * std_len:\n",
    "        cnt4 += 1\n",
    "        \n",
    "print(cnt2, cnt3, cnt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_sentences = []\n",
    "\n",
    "for vid, sentences in new_video2caption_step3.items():\n",
    "    if vid < 7010:\n",
    "        continue\n",
    "\n",
    "    for sid, sentence in enumerate(sentences):\n",
    "        words = sentence['caption'].strip().split()\n",
    "        if len(words) > avg_len + 3 * std_len:\n",
    "            multiple_sentences.append(\"{}, {}, {}\".format(vid, sid, sentence['caption']))\n",
    "            \n",
    "print(len(multiple_sentences))\n",
    "multiple_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"multiple_sentences.txt\", \"w\") as fo:\n",
    "    for line in multiple_sentences:\n",
    "        fo.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"multiple_sentences[700].txt\", \"r\") as fo:\n",
    "    cleaned_sentences = fo.readlines()\n",
    "    cleaned_sentences = [line.strip().lower() for line in cleaned_sentences]\n",
    "    \n",
    "cleaned_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(new_video2caption_step3.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "new_video2caption_step4 = copy.deepcopy(new_video2caption_step3)\n",
    "\n",
    "sent_set = set()\n",
    "vid_set = set()\n",
    "for line in cleaned_sentences:\n",
    "    vid, sid, sent = line.strip().split(\", \")\n",
    "    vid, sid = int(vid), int(sid)\n",
    "    sent = sent.strip()\n",
    "    if new_video2caption_step4[vid][sid]['caption'] != sent:\n",
    "        print('old: {}, new: {}'.format(new_video2caption_step4[vid][sid]['caption'], sent))\n",
    "        new_video2caption_step4[vid][sid]['caption'] = sent\n",
    "        sent_set.add(sid + vid * 100)\n",
    "        vid_set.add(vid)\n",
    "        \n",
    "\n",
    "for vid, sents in new_video2caption_step4.items():\n",
    "    if vid >= 7010:\n",
    "        continue\n",
    "    for sidx, s in enumerate(sents):\n",
    "        caption = \" \".join(s['caption'].strip().split()[:18])\n",
    "        if caption != s['caption']:\n",
    "            sent_set.add(vid * 100 + sidx)\n",
    "            vid_set.add(vid)\n",
    "        s['caption'] = caption\n",
    "    new_video2caption_step4[vid] = sents\n",
    "\n",
    "\n",
    "print(f\"modified sentences: {len(sent_set)}, videos: {len(vid_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('step4_videodatainfo_detailed.json', 'w') as fo:\n",
    "    json.dump(new_video2caption_step4, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video2caption_step4[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
